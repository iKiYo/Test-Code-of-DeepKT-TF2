{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "my DKT + tempo",
      "provenance": [],
      "collapsed_sections": [
        "lGd119p-09A7",
        "M9qFwaq_FYML",
        "g1aaRru71q-S",
        "JEGqcDNz4T-V"
      ],
      "toc_visible": true,
      "mount_file_id": "1DjKCKrBSQspyjXfjspPGBqR9sZZZI51F",
      "authorship_tag": "ABX9TyPJPZmsiHbPKY/RAYwwYro/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iKiYo/Test-Code-of-DeepKT-TF2/blob/master/my_DKT_%2B_tempo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGd119p-09A7",
        "colab_type": "text"
      },
      "source": [
        "### Download assistment 2012 dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9qFwaq_FYML",
        "colab_type": "text"
      },
      "source": [
        "#### use edudata, a downloader of IST educational datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTXFe8Ok7fze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install EduData"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SacFVb0l7h1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!edudata ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV16w6jB7qlu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!edudata download assistment-2012-2013-non-skill"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1aaRru71q-S",
        "colab_type": "text"
      },
      "source": [
        "#### Use stored data in Gdrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1BiMExH33i4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "assistment_2012_dataset = pd.read_csv(\"/content/drive/My Drive/master thesis/Datasets/assistment_dataset/2012-2013-data-with-predictions-4-final.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skvQZy5ZFlZO",
        "colab_type": "text"
      },
      "source": [
        "### Data statistic and preprocessing of assistment_2012, which contains timestamps of attempts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAWSBqF1GeRA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(assistment_2012_dataset))\n",
        "assistment_2012_dataset.head(1)\n",
        "print(list(assistment_2012_dataset.columns.values)) # get the list of column header"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLfy3ew9F1rv",
        "colab_type": "text"
      },
      "source": [
        "##### XXX: skill_id has more types than skill(name)??"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJcIO5tXABnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print( assistment_2012_dataset.skill_id.unique())\n",
        "print( assistment_2012_dataset.skill.unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uywK5DS96skB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print( assistment_2012_dataset[['user_id', 'skill', 'skill_id','problem_id','assignment_id','assistment_id']].nunique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69NwWiwxPhDz",
        "colab_type": "text"
      },
      "source": [
        "#### try out drop nan and check skill"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2AcU45PGNgL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assistment_2012_dataset_selected = pd.read_csv(\n",
        "    \"/content/drive/My Drive/master thesis/Datasets/assistment_dataset/2012-2013-data-with-predictions-4-final.csv\",\n",
        "    usecols=['problem_log_id', 'skill', 'problem_id', 'user_id', 'assignment_id', 'assistment_id', 'start_time', 'end_time', 'correct', 'attempt_count', 'skill_id'])\n",
        "print(len(assistment_2012_dataset_selected))\n",
        "assistment_2012_dataset_selected.head(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmhExQ8sNc4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = assistment_2012_dataset_selected[['skill', 'skill_id']].dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QJHqNoZOG3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.astype({'skill_id': 'int32'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ujCadKQOk9t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOtfqpwRQt6Q",
        "colab_type": "text"
      },
      "source": [
        "#### process timestamp columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7szdnhRGFqUK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sort by endtime\n",
        "selected_df =selected_df.sort_values(by=['end_time'])\n",
        "selected_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXI3EK3Wq8T_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "counts = selected_df['end_time'].value_counts()\n",
        "dub_time_df= selected_df[~selected_df['end_time'].isin(counts[counts < 2].index)]\n",
        "dub_time_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJVRPsP8utl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dub_time_df[dub_time_df['end_time'] == '2012-10-12 13:41:00.974']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xlSgYgNrkPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dub_time_df['end_time'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0sVusYm-nmYz"
      },
      "source": [
        "#### (drop NaN ) make a complete and minimum csv dataset for experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SA6I5Pz4nmY9",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "assist2012_preprocessed = pd.read_csv(\n",
        "    \"/content/drive/My Drive/master thesis/Datasets/assistment_dataset/2012-2013-data-with-predictions-4-final.csv\",\n",
        "    usecols=['assistment_id', 'user_id', 'start_time', 'end_time', 'correct', 'attempt_count', 'skill_id', 'skill'])\n",
        "print(len(assist2012_preprocessed))\n",
        "assist2012_preprocessed.head(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0JqyV_sonmZW",
        "colab": {}
      },
      "source": [
        "df = assist2012_preprocessed\n",
        "print(len(df))\n",
        "#df = df.drop_duplicates(subset=['problem_id','user_id','attempt_count'])\n",
        "df = df.drop_duplicates()\n",
        "print(len(df))\n",
        "df = df.dropna(subset=['skill_id', 'skill' ])\n",
        "# change 'correct' column into a boolean format as recommended in ASSIST dataset website\n",
        "#df['correct'] = (df['correct'] >= 1).astype(int)\n",
        "df = df[df[\"correct\"].isin([0, 1])]\n",
        "df = df.astype({'skill_id': 'int32'})\n",
        "print(len(df))\n",
        "df.nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAF876Zf3Qo2",
        "colab_type": "text"
      },
      "source": [
        "##### WARNING: 70% of attempts(labels) are correct"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ut5RkCLlnmZ0",
        "colab": {}
      },
      "source": [
        "df.correct.value_counts(normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OOzt2NkJnmaU",
        "colab": {}
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n3MnoORonmag",
        "colab": {}
      },
      "source": [
        "# remove users with a sequence length less than three\n",
        "counts = df['user_id'].value_counts()\n",
        "selected_df= df[~df['user_id'].isin(counts[counts < 3].index)]\n",
        "print(len(selected_df))\n",
        "selected_df.nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1rJKHahOnya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "selected_df.drop_duplicates()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GUffkyGJnmao",
        "colab": {}
      },
      "source": [
        "selected_df['user_id'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RC6kCbVunmay",
        "colab": {}
      },
      "source": [
        "tdf = selected_df[selected_df['user_id'] == 221324]\n",
        "#selected_df[\"timestamp\"] = pd.to_datetime([\"end_time\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xfQHR0g3nma_",
        "colab": {}
      },
      "source": [
        "skill_counts = selected_df['skill_id'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-LYF54pvnmbH",
        "colab": {}
      },
      "source": [
        "skill_counts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "99hBjokPnmbS",
        "colab": {}
      },
      "source": [
        "len(counts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uTwINV-Lnmbc",
        "colab": {}
      },
      "source": [
        "len(selected_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7o2QTsdynmbk",
        "colab": {}
      },
      "source": [
        "selected_df.nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l0OpenFjnmbs",
        "colab": {}
      },
      "source": [
        "df[df['attempt_count'] == 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjrCZ8LHe3o2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import sparse\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "data_name = \"/content/drive/My Drive/master thesis/Datasets/assistment_dataset/2012-2013-data-with-predictions-4-final.csv\"\n",
        "min_interactions_per_user = 0\n",
        "remove_nan_skills = True\n",
        "\n",
        "\n",
        "\"\"\"Preprocess ASSISTments dataset.\n",
        "\n",
        "Arguments:\n",
        "    data_name: \"assistments09\", \"assistments12\", \"assistments15\" or \"assistments17\"\n",
        "    min_interactions_per_user (int): minimum number of interactions per student\n",
        "    remove_nan_skills (bool): if True, remove interactions with no skill tag\n",
        "Outputs:\n",
        "    df (pandas DataFrame): preprocessed ASSISTments dataset with user_id, item_id,\n",
        "        timestamp and correct features\n",
        "    Q_mat (item-skill relationships sparse array): corresponding q-matrix\n",
        "\"\"\"\n",
        "#data_path = os.path.join(\"data\", data_name)\n",
        "#df = pd.read_csv(os.path.join(data_path, \"data.csv\"), encoding=\"ISO-8859-1\")\n",
        "df = pd.read_csv(os.path.join(data_name))\n",
        "data_name = \"assistments12\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9DrTetHfM3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.rename(columns={\"problem_id\": \"item_id\"})\n",
        "df[\"timestamp\"] = pd.to_datetime(df[\"start_time\"])\n",
        "print(df.dtypes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3TsiWocz-79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[\"timestamp\"] = df[\"timestamp\"] - df[\"timestamp\"].min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4W5OpZ9r1AvE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[\"timestamp\"] = df[\"timestamp\"].apply(lambda x: x.total_seconds()).astype(np.int64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2m6oS8_z3mF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sort data temporally\n",
        "if data_name in [\"assistments12\", \"assistments17\"]:\n",
        "    df.sort_values(by=\"timestamp\", inplace=True)\n",
        "elif data_name == \"assistments09\":\n",
        "    df.sort_values(by=\"order_id\", inplace=True)\n",
        "elif data_name == \"assistments15\":\n",
        "    df.sort_values(by=\"log_id\", inplace=True)\n",
        "\n",
        "# Filter too short sequences\n",
        "df = df.groupby(\"user_id\").filter(lambda x: len(x) >= min_interactions_per_user)\n",
        "\n",
        "# Remove continuous outcomes\n",
        "df = df[df[\"correct\"].isin([0, 1])]\n",
        "df[\"correct\"] = df[\"correct\"].astype(np.int32)\n",
        "\n",
        "# Filter nan skills\n",
        "if remove_nan_skills:\n",
        "    df = df[~df[\"skill_id\"].isnull()]\n",
        "else:\n",
        "    df.ix[df[\"skill_id\"].isnull(), \"skill_id\"] = -1\n",
        "\n",
        "df[\"user_id\"] = np.unique(df[\"user_id\"], return_inverse=True)[1]\n",
        "df[\"item_id\"] = np.unique(df[\"item_id\"], return_inverse=True)[1]\n",
        "df[\"skill_id\"] = np.unique(df[\"skill_id\"], return_inverse=True)[1]\n",
        "\n",
        "# Build Q-matrix\n",
        "Q_mat = np.zeros((len(df[\"item_id\"].unique()), len(df[\"skill_id\"].unique())))\n",
        "for item_id, skill_id in df[[\"item_id\", \"skill_id\"]].values:\n",
        "    Q_mat[item_id, skill_id] = 1\n",
        "\n",
        "\n",
        "\n",
        "df = df[['user_id', 'item_id', 'timestamp', 'correct']]\n",
        "df.reset_index(inplace=True, drop=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDNJHOk01xTM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = \"./\"\n",
        "\n",
        "# Save data\n",
        "sparse.save_npz(os.path.join(data_path, \"q_mat.npz\"), sparse.csr_matrix(Q_mat))\n",
        "df.to_csv(os.path.join(data_path, \"preprocessed_data.csv\"), sep=\"\\t\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBw6fH-g14eu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre_df = pd.read_csv(\"/content/preprocessed_data.csv\", sep=\"\\t\")\n",
        "pre_df.nunique()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzRubGOpAcSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "from random import shuffle\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "\n",
        "def set_random_seeds(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    random.seed(seed)\n",
        "    \n",
        "    \n",
        "def get_data(df, train_split=0.8):\n",
        "    num_items = df[\"item_id\"].nunique()\n",
        "    data = [(torch.tensor(u_df[\"item_id\"].values, dtype=torch.long),\n",
        "             torch.tensor(u_df[\"correct\"].values, dtype=torch.long))\n",
        "            for _, u_df in df.groupby(\"user_id\")]\n",
        "    data = [(torch.cat((torch.zeros(1, dtype=torch.long), item_ids + labels * num_items + 1))[:-1], item_ids, labels)\n",
        "            for (item_ids, labels) in data]\n",
        "    shuffle(data)\n",
        "\n",
        "    # Train-test split across users\n",
        "    train_size = int(train_split * len(data))\n",
        "    train_data, val_data = data[:train_size], data[train_size:]\n",
        "    return train_data, val_data\n",
        "\n",
        "\n",
        "def prepare_batches(data, batch_size):\n",
        "    \"\"\"Prepare batches grouping padded sequences.\n",
        "    \n",
        "    Arguments:\n",
        "        data (list of tuples of torch Tensor)\n",
        "        batch_size (int): number of sequences per batch\n",
        "        \n",
        "    Output:\n",
        "        batches (list of tuples of torch Tensor)\n",
        "    \"\"\"\n",
        "    shuffle(data)\n",
        "    batches = []\n",
        "\n",
        "    for k in range(0, len(data), batch_size):\n",
        "        batch = data[k:k + batch_size]\n",
        "        inputs, item_ids, labels = zip(*batch)\n",
        "\n",
        "        inputs = pad_sequence(inputs, batch_first=True, padding_value=0)     # Pad with 0\n",
        "        item_ids = pad_sequence(item_ids, batch_first=True, padding_value=0) # Don't care\n",
        "        labels = pad_sequence(labels, batch_first=True, padding_value=-1)    # Pad with -1\n",
        "\n",
        "        batches.append([inputs, item_ids, labels])\n",
        "        \n",
        "    return batches\n",
        "\n",
        "\n",
        "def compute_auc(preds, item_ids, labels):\n",
        "    labels = labels.view(-1)\n",
        "    item_ids = item_ids.view(-1)[labels >= 0]\n",
        "    preds = preds.view(-1, preds.shape[-1])[labels >= 0]\n",
        "    preds = preds[torch.arange(preds.shape[0]), item_ids]\n",
        "    labels = labels[labels >= 0].float()\n",
        "\n",
        "    if len(torch.unique(labels)) == 1: # Only one class\n",
        "        auc = accuracy_score(labels, preds.round())\n",
        "    else:\n",
        "        auc = roc_auc_score(labels, preds)\n",
        "    return auc\n",
        "\n",
        "\n",
        "def compute_loss(preds, item_ids, labels, criterion):\n",
        "    labels = labels.view(-1)\n",
        "    item_ids = item_ids.view(-1)[labels >= 0]\n",
        "    preds = preds.view(-1, preds.shape[-1])[labels >= 0]\n",
        "    preds = preds[torch.arange(preds.shape[0]), item_ids]\n",
        "    labels = labels[labels >= 0].float()\n",
        "    return criterion(preds, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbLe4qZJAUhB",
        "colab_type": "text"
      },
      "source": [
        "#### sample data for debug"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y06XW-GyLlVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data dependent parameters\n",
        "num_student = 1000\n",
        "num_skills = 5 #M\n",
        "max_sequence_length =  6 # T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGY8T9UK4QKI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# q question ids\n",
        "raw_inputs = np.array([\n",
        "    [1, 3, 4],\n",
        "   [3, 4, 2, 1, 2],\n",
        "   [3, 1, 1, 4, 5, 2],\n",
        "])\n",
        "# a answer or attempts on the questions\n",
        "raw_labels =  np.array([\n",
        "    [1, 1, 1],\n",
        "   [0, 0, 0, 1, 1],\n",
        "   [0, 1, 1, 1, 0, 1]\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "print(F\"raw_inputs \\n{raw_inputs}\")\n",
        "print(F\"raw_labels \\n{raw_labels}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwmf7Qg3AXYK",
        "colab_type": "text"
      },
      "source": [
        "##### tf.Tensor/ndarray format data preprocessing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_UUYe9WyMll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# padded_q\n",
        "# padding is -1 and adjust indeces of tensors\n",
        "padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    raw_inputs, maxlen=max_sequence_length, padding=\"post\", value=0\n",
        ")\n",
        "# Warning: supposing the question ids 1> , \n",
        "padded_inputs = padded_inputs - 1\n",
        "print(F\"padded_inputs :\\n{padded_inputs}\")\n",
        "\n",
        "# padded_a\n",
        "# padding is 1 to set the padding of x_t to -1\n",
        "padded_labels= tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    raw_labels, maxlen=max_sequence_length, padding=\"post\", value=1\n",
        ")\n",
        "padded_labels=tf. convert_to_tensor(padded_labels)\n",
        "print(F\"padded_labels:\\n {padded_labels}\") # q_t\n",
        "print(padded_labels.dtype)\n",
        "print()\n",
        "\n",
        "\"\"\"\n",
        "M to 2M vector\n",
        "binary => correct columns + incorrect columns \n",
        "\"\"\"\n",
        "# raw_x_t = M*(1 - a_t) + q_t \n",
        "signaled_input = num_skills * ( 1 - padded_labels) + padded_inputs\n",
        "print(F\"signaled_input:\\n{signaled_input}\")\n",
        "print()\n",
        "\n",
        "# x_t\n",
        "one_hot_input = tf.one_hot(signaled_input, depth=num_skills*2, axis=-1)\n",
        "print(F\"x_t sample:\\n{one_hot_input.numpy()[1]}\")\n",
        "print(one_hot_input.numpy().shape)\n",
        "print()\n",
        "\n",
        "# delta(q_t)\n",
        "one_hot_q_t = tf.one_hot(padded_inputs, depth=num_skills, axis=-1)\n",
        "print(F\"delta(q_t) sample:\\n{one_hot_q_t.numpy()[1]}\")\n",
        "one_hot_q_t.numpy().shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUowd8EvF4zF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "signaled_sample[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xv8aARxR_mtb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(signaled_sample)):\n",
        "  for k in range(len(padded_sample[i])):\n",
        "      print(signaled_sample[i][k])\n",
        "      print(len(signaled_sample[i][k]), len(signaled_sample[i][k]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCmNeS1YKPTQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "q, x, delta_q = signaled_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mef66Zu6CP9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "u_df = df.groupby('user_id')\n",
        "u_df.count()['timestamp'].median()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gJ7iUUT1eKz",
        "colab_type": "text"
      },
      "source": [
        "#### check median of attempts length(T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCZcF_D1Pdq7",
        "colab_type": "text"
      },
      "source": [
        "### Complete preprocess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1X0u3DOv1J5",
        "colab_type": "text"
      },
      "source": [
        "###### preprocess with pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDOsIfZDPirw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "\n",
        "assist2012_preprocessed = pd.read_csv(\n",
        "    \"/content/drive/My Drive/master thesis/Datasets/assistment_dataset/2012-2013-data-with-predictions-4-final.csv\",\n",
        "    usecols=['user_id', 'skill_id', 'correct', 'end_time', 'attempt_count'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9PXbyy3RYsm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "2b3e6440-ddee-41a2-bdd4-c5a76effec32"
      },
      "source": [
        "print(len(assist2012_preprocessed))\n",
        "assist2012_preprocessed.head(1)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6123270\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>end_time</th>\n",
              "      <th>correct</th>\n",
              "      <th>attempt_count</th>\n",
              "      <th>skill_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>61394</td>\n",
              "      <td>2012-09-28 15:11:36.856</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id                 end_time  correct  attempt_count  skill_id\n",
              "0    61394  2012-09-28 15:11:36.856      1.0              1       NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMigt93JPoBe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "58f90a21-09be-4361-9b93-a63f49dd4bc0"
      },
      "source": [
        "df = assist2012_preprocessed\n",
        "\n",
        "# drop NaN skill_ids \n",
        "df = df.dropna(subset = ['skill_id'])\n",
        "# or fill NaN\n",
        "#df = df.fillna(value={'skill_id': 999})\n",
        "#df = df.astype({'skill_id': 'int32'})\n",
        "print(len(df))\n",
        "df.nunique()\n",
        "df"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2711813\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>end_time</th>\n",
              "      <th>correct</th>\n",
              "      <th>attempt_count</th>\n",
              "      <th>skill_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>61394</td>\n",
              "      <td>2012-10-09 11:02:13.182</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>54.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>61394</td>\n",
              "      <td>2013-03-07 10:53:28.661</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>279.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>61394</td>\n",
              "      <td>2013-08-20 19:55:21.753</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>79.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>76592</td>\n",
              "      <td>2012-12-12 21:01:07.536</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>86.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>78401</td>\n",
              "      <td>2012-10-16 10:31:55.445</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>311.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6123259</th>\n",
              "      <td>227693</td>\n",
              "      <td>2013-08-29 13:20:52.98</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>94.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6123260</th>\n",
              "      <td>227788</td>\n",
              "      <td>2013-08-29 16:19:08.388</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>75.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6123262</th>\n",
              "      <td>227839</td>\n",
              "      <td>2013-08-31 15:15:08.024</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>34.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6123264</th>\n",
              "      <td>227908</td>\n",
              "      <td>2013-08-31 00:25:16.236</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>67.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6123267</th>\n",
              "      <td>228039</td>\n",
              "      <td>2013-08-30 11:30:05.517</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>277.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2711813 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         user_id                 end_time  correct  attempt_count  skill_id\n",
              "1          61394  2012-10-09 11:02:13.182      1.0              1      54.0\n",
              "2          61394  2013-03-07 10:53:28.661      0.0              1     279.0\n",
              "3          61394  2013-08-20 19:55:21.753      1.0              1      79.0\n",
              "5          76592  2012-12-12 21:01:07.536      1.0              1      86.0\n",
              "7          78401  2012-10-16 10:31:55.445      1.0              1     311.0\n",
              "...          ...                      ...      ...            ...       ...\n",
              "6123259   227693   2013-08-29 13:20:52.98      1.0              1      94.0\n",
              "6123260   227788  2013-08-29 16:19:08.388      1.0              1      75.0\n",
              "6123262   227839  2013-08-31 15:15:08.024      1.0              1      34.0\n",
              "6123264   227908  2013-08-31 00:25:16.236      0.0              3      67.0\n",
              "6123267   228039  2013-08-30 11:30:05.517      0.0              1     277.0\n",
              "\n",
              "[2711813 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dMVMDbgQEOD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "75c3c0f0-66ad-4cd3-9cbd-b22d324b0f5c"
      },
      "source": [
        "df = df[df[\"correct\"].isin([0, 1])]\n",
        "df['correct'] = (df['correct'] >= 1).astype(int)\n",
        "\n",
        "df"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>end_time</th>\n",
              "      <th>correct</th>\n",
              "      <th>attempt_count</th>\n",
              "      <th>skill_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>61394</td>\n",
              "      <td>2012-10-09 11:02:13.182</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>54.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>61394</td>\n",
              "      <td>2013-03-07 10:53:28.661</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>279.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>61394</td>\n",
              "      <td>2013-08-20 19:55:21.753</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>76592</td>\n",
              "      <td>2012-12-12 21:01:07.536</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>86.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>78401</td>\n",
              "      <td>2012-10-16 10:31:55.445</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>311.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6123259</th>\n",
              "      <td>227693</td>\n",
              "      <td>2013-08-29 13:20:52.98</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>94.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6123260</th>\n",
              "      <td>227788</td>\n",
              "      <td>2013-08-29 16:19:08.388</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>75.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6123262</th>\n",
              "      <td>227839</td>\n",
              "      <td>2013-08-31 15:15:08.024</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>34.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6123264</th>\n",
              "      <td>227908</td>\n",
              "      <td>2013-08-31 00:25:16.236</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>67.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6123267</th>\n",
              "      <td>228039</td>\n",
              "      <td>2013-08-30 11:30:05.517</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>277.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2711602 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         user_id                 end_time  correct  attempt_count  skill_id\n",
              "1          61394  2012-10-09 11:02:13.182        1              1      54.0\n",
              "2          61394  2013-03-07 10:53:28.661        0              1     279.0\n",
              "3          61394  2013-08-20 19:55:21.753        1              1      79.0\n",
              "5          76592  2012-12-12 21:01:07.536        1              1      86.0\n",
              "7          78401  2012-10-16 10:31:55.445        1              1     311.0\n",
              "...          ...                      ...      ...            ...       ...\n",
              "6123259   227693   2013-08-29 13:20:52.98        1              1      94.0\n",
              "6123260   227788  2013-08-29 16:19:08.388        1              1      75.0\n",
              "6123262   227839  2013-08-31 15:15:08.024        1              1      34.0\n",
              "6123264   227908  2013-08-31 00:25:16.236        0              3      67.0\n",
              "6123267   228039  2013-08-30 11:30:05.517        0              1     277.0\n",
              "\n",
              "[2711602 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpM0j-ldUqA8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ab25505b-887a-44d4-e0dd-72291b3f6961"
      },
      "source": [
        "# delete user with only one attempt\n",
        "counts = df['user_id'].value_counts()\n",
        "df= df[~df['user_id'].isin(counts[counts < 2].index)]\n",
        "\n",
        "# print(selected_df['user_id'].value_counts())\n",
        "max_sequence_length=  df['user_id'].value_counts().max()\n",
        "# print(max_sequence_length)\n",
        "# print(selected_df['skill_id'].value_counts())\n",
        "# sample entry\n",
        "# df[df['user_id'] == 221324]\n",
        "len(df.drop_duplicates()), len(df)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2710702"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVfsAFo8Spp9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "56878828-9500-4519-e0dc-789996635552"
      },
      "source": [
        "# sort by endtime(timestamp)\n",
        "df =df.sort_values(by=['end_time'])\n",
        "df"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>end_time</th>\n",
              "      <th>correct</th>\n",
              "      <th>attempt_count</th>\n",
              "      <th>skill_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2012329</th>\n",
              "      <td>169036</td>\n",
              "      <td>2012-09-01 00:01:48.186552</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>81.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1582259</th>\n",
              "      <td>172027</td>\n",
              "      <td>2012-09-01 00:02:06.478</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>358.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3961249</th>\n",
              "      <td>169036</td>\n",
              "      <td>2012-09-01 00:03:02.788824</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>81.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4703521</th>\n",
              "      <td>172027</td>\n",
              "      <td>2012-09-01 00:03:53.329</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>358.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6065676</th>\n",
              "      <td>169036</td>\n",
              "      <td>2012-09-01 00:04:23.367864</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>81.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>752604</th>\n",
              "      <td>225337</td>\n",
              "      <td>2013-10-06 20:49:25.159</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>312.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2057397</th>\n",
              "      <td>218970</td>\n",
              "      <td>2013-10-08 16:56:22.989</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>378.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3288044</th>\n",
              "      <td>218970</td>\n",
              "      <td>2013-10-08 17:25:11.741</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>346.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1817838</th>\n",
              "      <td>218970</td>\n",
              "      <td>2013-10-08 17:28:21.378</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>378.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>406102</th>\n",
              "      <td>222386</td>\n",
              "      <td>2013-10-09 20:00:02.411</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>312.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2710702 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         user_id                    end_time  correct  attempt_count  skill_id\n",
              "2012329   169036  2012-09-01 00:01:48.186552        1              1      81.0\n",
              "1582259   172027     2012-09-01 00:02:06.478        0              3     358.0\n",
              "3961249   169036  2012-09-01 00:03:02.788824        0              1      81.0\n",
              "4703521   172027     2012-09-01 00:03:53.329        1              1     358.0\n",
              "6065676   169036  2012-09-01 00:04:23.367864        0              1      81.0\n",
              "...          ...                         ...      ...            ...       ...\n",
              "752604    225337     2013-10-06 20:49:25.159        0              6     312.0\n",
              "2057397   218970     2013-10-08 16:56:22.989        0              1     378.0\n",
              "3288044   218970     2013-10-08 17:25:11.741        0              1     346.0\n",
              "1817838   218970     2013-10-08 17:28:21.378        0              2     378.0\n",
              "406102    222386     2013-10-09 20:00:02.411        0              2     312.0\n",
              "\n",
              "[2710702 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH3Xnx8iTUWb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "905ffe6e-c9f4-4ad2-b480-c0eee481bc8a"
      },
      "source": [
        "# enumerate and renumber the remain student and skill IDs\n",
        "df['user_id'], _ = pd.factorize(df['user_id'], sort=False)\n",
        "df['skill_id'], _ = pd.factorize(df['skill_id'], sort=False)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['user_id', 'end_time', 'correct', 'attempt_count', 'skill_id']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZnbKGjXUffu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b5f1ccf0-0760-4864-dcf1-72c20e69b613"
      },
      "source": [
        "# get N, M, T\n",
        "num_students, num_skills, _ = df.nunique()\n",
        "assert max_sequence_length, df['user_id'].value_counts().max()\n",
        "\n",
        "print(num_students, num_skills, max_sequence_length)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28118 265 2089\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2aloMz2U1U4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cross skill id with answer to form a synthetic feature\n",
        "df['x'] = df['skill_id'] * 2 + df['correct']"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8k9Zc60vgc-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv(\"/content/drive/My Drive/master thesis/Datasets/assistment_dataset/assist12_4cols_noNaNskill.csv\", index=False)"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_YNKQB6eebB",
        "colab_type": "text"
      },
      "source": [
        "###### preprocess in the tf.data format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wa-IyEdIE0yM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(tf.test.is_gpu_available())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05uEOM34v7l9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/My Drive/master thesis/Datasets/assistment_dataset/assist12_4cols_noNaNskill.csv\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrP3igGTFFyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get N, M, T\n",
        "num_students, num_skills, _, _ = df.nunique()\n",
        "max_sequence_length=  df['user_id'].value_counts().max()\n",
        "print(num_students, num_skills, max_sequence_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2MVAmSdelQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 25"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE9w-OKGUwzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq = df.groupby('user_id').apply(\n",
        "    lambda r: (\n",
        "        r['x'].values[:-1],\n",
        "        r['skill_id'].values[1:],\n",
        "        r['correct'].values[1:],\n",
        "    )\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCz1Rd_jVMwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert num_students, len(seq)\n",
        "seq[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pf_6TnomWdWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 5 - Get Tensorflow Dataset\n",
        "dataset = tf.data.Dataset.from_generator(\n",
        "    generator=lambda: seq,\n",
        "    output_types=(tf.int32, tf.int32, tf.int32)\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9FZaJjOWmHF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "00c62936-2d17-48ee-a98e-fc90313d57b8"
      },
      "source": [
        "dataset.shuffle(buffer_size=num_students)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<ShuffleDataset shapes: (<unknown>, <unknown>, <unknown>), types: (tf.int32, tf.int32, tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzxRcN1LXbTm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformed_dataset  = dataset.map(\n",
        "    lambda feat, skill, label: (\n",
        "        tf.one_hot(feat, depth=num_skills*2), # x\n",
        "        tf.one_hot(skill, depth=num_skills, axis=-1), # q\n",
        "        tf.expand_dims(label, -1) # a \n",
        "    )\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dftKrOyyace0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "padded_sample = list(transformed_dataset.take(3).as_numpy_iterator())\n",
        "for i in range(3):\n",
        "  print(padded_sample[0][i].T)\n",
        "  print(np.array(padded_sample[0][i].T).shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU9rcSlHbXrW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fd84d54a-5a81-4d8b-9f0f-5f453a515d37"
      },
      "source": [
        "padding_length = max_sequence_length\n",
        "padded_dataset = transformed_dataset.padded_batch(\n",
        "        batch_size=batch_size,\n",
        "        padding_values=(0.,0.,-1),\n",
        "        padded_shapes=([padding_length, 2*num_skills], [padding_length, num_skills], [padding_length, 1]),\n",
        "        drop_remainder=True\n",
        "    )\n",
        "padded_dataset"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PaddedBatchDataset shapes: ((25, 2089, 530), (25, 2089, 265), (25, 2089, 1)), types: (tf.float32, tf.float32, tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hRXGF0ScUUa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "eaacec88-93ab-4272-899f-58a7aade0fba"
      },
      "source": [
        "# to dict dataset\n",
        "input_label_dataset = padded_dataset.map(\n",
        "        lambda x, delta_q, a : (\n",
        "             {\"x\" : x,\n",
        "              \"q\" : delta_q},\n",
        "             { \"outputs\" : a}\n",
        "        )\n",
        "    )\n",
        "print(input_label_dataset)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<MapDataset shapes: ({x: (25, 2089, 530), q: (25, 2089, 265)}, {outputs: (25, 2089, 1)}), types: ({x: tf.float32, q: tf.float32}, {outputs: tf.int32})>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9rCSpBgKBeO",
        "colab_type": "text"
      },
      "source": [
        "##### define split fucntion into train/test/valid\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9phziecKEkR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "code from https://github.com/lccasagrande/Deep-Knowledge-Tracing\n",
        "\"\"\"\n",
        "\n",
        "def split_dataset(dataset, total_size, test_fraction, val_fraction=None):\n",
        "    def split(dataset, split_size):\n",
        "        split_set = dataset.take(split_size)\n",
        "        dataset = dataset.skip(split_size)\n",
        "        return dataset, split_set\n",
        "\n",
        "    if not 0 < test_fraction < 1:\n",
        "        raise ValueError(\"test_fraction must be between (0, 1)\")\n",
        "\n",
        "    if val_fraction is not None and not 0 < val_fraction < 1:\n",
        "        raise ValueError(\"val_fraction must be between (0, 1)\")\n",
        "\n",
        "    test_size = np.ceil(test_fraction * total_size)\n",
        "    train_size = total_size - test_size\n",
        "\n",
        "    if test_size == 0 or train_size == 0:\n",
        "        raise ValueError(\n",
        "            \"The train and test datasets must have at least 1 element. Reduce the split fraction or get more data.\")\n",
        "\n",
        "    train_set, test_set = split(dataset, test_size)\n",
        "\n",
        "    val_set = None\n",
        "    if val_fraction:\n",
        "        val_size = np.ceil(train_size * val_fraction)\n",
        "        train_set, val_set = split(train_set, val_size)\n",
        "\n",
        "    return train_set, test_set, val_set\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJXEXBiE3kbs",
        "colab_type": "text"
      },
      "source": [
        "## Model Codes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aaPHqc3iqvV",
        "colab_type": "text"
      },
      "source": [
        "### try neptune.ai"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZX4sRNWnh0n8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install neptune-client"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SFLjUHqT_Cu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env NEPTUNE_API_TOKEN=\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chxq0lB6i1CE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import neptune\n",
        "neptune.init('ikiyo/sandbox')\n",
        "\n",
        "with neptune.create_experiment():\n",
        "    neptune.send_metric('auc', 0.92)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee3s94GgmFq0",
        "colab_type": "text"
      },
      "source": [
        "### DKT code of exepriments of spaced tempral effect\n",
        "https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwiU6pDN7M_rAhW_A2MBHU3gD3AQFjABegQIARAB&url=https%3A%2F%2Feducationaldatamining.org%2Ffiles%2Fconferences%2FEDM2020%2Fpapers%2Fpaper_242.pdf&usg=AOvVaw1frKbFoVwfcA-a4XGEAw2i"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Kl0hrwhzvFi",
        "colab_type": "text"
      },
      "source": [
        "!git clone https://github.com/thosgt/kt-algos.git"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyLnM2Ajs1id",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r \"/content/drive/My Drive/master thesis/Source code/kt-algos\" ./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tHnNSGJmV8p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd kt-algos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUEq1UQWmoJA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JarHCQDlm0ee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p data/assistments12"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Guxbn-eLnAsj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp \"/content/drive/My Drive/master thesis/Datasets/assistment_dataset/2012-2013-data-with-predictions-4-final.csv\" ./data/assistments12/data.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klYhbOAhnOyW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python prepare_data.py --dataset assistments12 --remove_nan_skills"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mto_1wKtXIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python train_dkt.py --dataset assistments12 --embed_inputs --embed_size=100 --hid_size=100 --batch_size=5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqSRIr-ORwS0",
        "colab_type": "text"
      },
      "source": [
        "### DKT in TF2 from GitHub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPT2pLfhR4uz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/lccasagrande/Deep-Knowledge-Tracing.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_bt2MUJSPUD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd Deep-Knowledge-Tracing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ke2GfNEhS74S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/Deep-Knowledge-Tracing/examples/data/ASSISTments_skill_builder_data.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXYv9r7JenlN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install -e .[tf_gpu]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0uHH-HaSYcC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python ./run_dkt.py -f \"/content/Deep-Knowledge-Tracing/examples/data/ASSISTments_skill_builder_data.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hh4TfZsDBA0z",
        "colab_type": "text"
      },
      "source": [
        "### iKiYo DKT in TF2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvaPwZzEBEhz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(tf.test.is_gpu_available())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgabE1KpHRi9",
        "colab_type": "text"
      },
      "source": [
        "##### build model function base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MVp_U2385Mvx",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(tf.test.is_gpu_available())\n",
        "df = pd.read_csv(\"/content/drive/My Drive/master thesis/Datasets/assistment_dataset/assist12_4cols_noNaNskill.csv\")\n",
        "\n",
        "# get N, M, T\n",
        "num_students, num_skills, _, _ = df.nunique()\n",
        "max_sequence_length=  df['user_id'].value_counts().max()\n",
        "print(num_students, num_skills, max_sequence_length)\n",
        "batch_size = 25\n",
        "seq = df.groupby('user_id').apply(\n",
        "    lambda r: (\n",
        "        r['x'].values[:-1],\n",
        "        r['skill_id'].values[1:],\n",
        "        r['correct'].values[1:],\n",
        "    )\n",
        ")\n",
        "assert num_students, len(seq)\n",
        "seq[0]\n",
        "\n",
        "# Step 5 - Get Tensorflow Dataset\n",
        "dataset = tf.data.Dataset.from_generator(\n",
        "    generator=lambda: seq,\n",
        "    output_types=(tf.int32, tf.int32, tf.int32)\n",
        ")\n",
        "dataset.shuffle(buffer_size=num_students)\n",
        "\n",
        "transformed_dataset  = dataset.map(\n",
        "    lambda feat, skill, label: (\n",
        "        tf.one_hot(feat, depth=num_skills*2), # x\n",
        "        tf.one_hot(skill, depth=num_skills, axis=-1), # q\n",
        "        tf.expand_dims(label, -1) # a \n",
        "    )\n",
        ")\n",
        "\n",
        "padded_sample = list(transformed_dataset.take(3).as_numpy_iterator())\n",
        "\n",
        "for i in range(3):\n",
        "  print(padded_sample[0][i].T)\n",
        "  print(np.array(padded_sample[0][i].T).shape)\n",
        "\n",
        "padding_length = max_sequence_length\n",
        "padded_dataset = transformed_dataset.padded_batch(\n",
        "        batch_size=batch_size,\n",
        "        padding_values=(0.,0.,-1),\n",
        "        padded_shapes=([padding_length, 2*num_skills], [padding_length, num_skills], [padding_length, 1]),\n",
        "        drop_remainder=True\n",
        "    )\n",
        "padded_dataset\n",
        "\n",
        "# to dict dataset\n",
        "input_label_dataset = padded_dataset.map(\n",
        "        lambda x, delta_q, a : (\n",
        "             {\"x\" : x,\n",
        "              \"q\" : delta_q},\n",
        "             { \"outputs\" : a}\n",
        "        )\n",
        "    )\n",
        "print(input_label_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m82Qx-_SM4vr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset, test_dataset, val_dataset = split_dataset(input_label_dataset, total_size=num_batches, test_fraction=0.1, val_fraction=0.2)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc_r6iO7RAXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_dataset.element_spec)\n",
        "print(list(train_dataset.take(1).as_numpy_iterator()))\n",
        "#print(list(test_dataset.take(1).as_numpy_iterator()))\n",
        "#print(list(valid_dataset.take(1).as_numpy_iterator()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfiNPErQkk5q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9f2ada1d-7f95-411c-866d-fa168e05d77b"
      },
      "source": [
        "# model parmaeters\n",
        "hidden_units=200 \n",
        "dropout_rate=0.2\n",
        "embed_dim = 200\n",
        "learning_rate = 0.005\n",
        "\n",
        "num_students, num_skills, max_sequence_length"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28118, 265, 2089)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fCCzLyC7J7S",
        "colab_type": "text"
      },
      "source": [
        "https://www.tensorflow.org/guide/keras/train_and_evaluate#passing_data_to_multi-input_multi-output_models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4_e6EnMHVM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# definition of input tensor shape and layers\n",
        "x = tf.keras.Input(shape=(max_sequence_length, num_skills*2), name='x')\n",
        "q = tf.keras.Input(shape=(max_sequence_length, num_skills), name='q')\n",
        "emb =  layers.Dense(embed_dim, trainable=False, \n",
        "                                                  kernel_initializer=tf.keras.initializers.RandomNormal(seed=777),\n",
        "                                                  input_shape=(None, max_sequence_length, num_skills*2))\n",
        "mask = layers.Masking(mask_value=0, input_shape=(max_sequence_length, embed_dim))\n",
        "lstm =  layers.LSTM(hidden_units, return_sequences=True)\n",
        "out_dropout =  layers.TimeDistributed(layers.Dropout(dropout_rate))\n",
        "out_sigmoid =  layers.TimeDistributed(layers.Dense(num_skills,  activation='sigmoid'))\n",
        "dot =  layers.Multiply()\n",
        "# HACK: the shape of q does not fit to Timedistributed operation(may be correct?)\n",
        "# dot =  layers.TimeDistributed(layers.Multiply())\n",
        "\n",
        "reduce_sum =  layers.Dense(1, trainable=False, \n",
        "                                                  kernel_initializer=tf.keras.initializers.constant(value=1),\n",
        "                                                  input_shape=(None, max_sequence_length,num_skills))\n",
        "# reshape layer does not work as graph  # reshape_l = layers.Reshape((-1,6),dynamic=False)#, \n",
        "final_mask =   layers.TimeDistributed(\n",
        "layers.Masking(mask_value=0, input_shape=(None, max_sequence_length,1))\n",
        ",name='outputs')\n",
        "\n",
        "\n",
        "# define graph\n",
        "n = emb(x)\n",
        "masked_n = mask(n)\n",
        "h = lstm(masked_n) \n",
        "o = out_dropout(h)\n",
        "y_pred = out_sigmoid(o)\n",
        "y_pred = dot([y_pred, q])\n",
        "# HACK: without using layer(tf.reduce) might be faster\n",
        "# y_pred = reduce_sum(y_pred, axis=2)\n",
        "y_pred = reduce_sum(y_pred)\n",
        "outputs = final_mask(y_pred)\n",
        "#  KEEP: another approach for final mask\n",
        "# patch initial mask by boolean_mask(tensor, mask)\n",
        "#tf.boolean_mask(y_pred, masked_n._keras_mask)\n",
        "#y_pred._keras_mask=masked_n._keras_mask\n",
        "\n",
        "\n",
        "# build model\n",
        "model = keras.Model(inputs=[x, q], outputs=outputs)\n",
        "\n",
        "\n",
        "# comile model\n",
        "# set Reduction.SUM for distributed traning\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.SUM),\n",
        "              optimizer=tf.optimizers.SGD(learning_rate=learning_rate),\n",
        "                # metrics=[tf.keras.metrics.AUC()])\n",
        "              metrics=[tf.keras.metrics.AUC(),tf.keras.metrics.BinaryCrossentropy()]) # keep BCEntropyfor debug"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6J7kNR8IjKXO",
        "colab_type": "text"
      },
      "source": [
        "##### train model on assist12 dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEi36C8MjHWK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.predict(train_dataset.take(1))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0MqnbtNAl1-",
        "colab_type": "text"
      },
      "source": [
        "###### measure the perfomace time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoVl6F4VAsBF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "class CustomCallback(keras.callbacks.Callback):\n",
        "    # def on_train_begin(self, logs=None):\n",
        "    #     keys = list(logs.keys())\n",
        "    #     print(\"Starting training; got log keys: {}\".format(keys))\n",
        "\n",
        "    # def on_train_end(self, logs=None):\n",
        "    #     keys = list(logs.keys())\n",
        "    #     print(\"Stop training; got log keys: {}\".format(keys))\n",
        "\n",
        "    # def on_epoch_begin(self, epoch, logs=None):\n",
        "    #     keys = list(logs.keys())\n",
        "    #     print(\"Start epoch {} of training; got log keys: {}\".format(epoch, keys))\n",
        "\n",
        "    # def on_epoch_end(self, epoch, logs=None):\n",
        "    #     keys = list(logs.keys())\n",
        "    #     print(\"End epoch {} of training; got log keys: {}\".format(epoch, keys))\n",
        "\n",
        "    # def on_test_begin(self, logs=None):\n",
        "    #     keys = list(logs.keys())\n",
        "    #     print(\"Start testing; got log keys: {}\".format(keys))\n",
        "\n",
        "    # def on_test_end(self, logs=None):\n",
        "    #     keys = list(logs.keys())\n",
        "    #     print(\"Stop testing; got log keys: {}\".format(keys))\n",
        "\n",
        "    # def on_predict_begin(self, logs=None):\n",
        "    #     keys = list(logs.keys())\n",
        "    #     print(\"Start predicting; got log keys: {}\".format(keys))\n",
        "\n",
        "    # def on_predict_end(self, logs=None):\n",
        "    #     keys = list(logs.keys())\n",
        "    #     print(\"Stop predicting; got log keys: {}\".format(keys))\n",
        "\n",
        "    def on_train_batch_begin(self, batch, logs=None):\n",
        "        self.batch_start_time = time.time()\n",
        "\n",
        "    def on_train_batch_end(self, batch, logs=None):\n",
        "        print(F\" time {time.time()-self.batch_start_time :.3f} sec\")\n",
        "\n",
        "    def on_test_batch_begin(self, batch, logs=None):\n",
        "        self.batch_start_time = time.time()\n",
        "\n",
        "    def on_test_batch_end(self, batch, logs=None):\n",
        "        print(F\" time {time.time()-self.batch_start_time :.3f} sec\")\n",
        "\n",
        "    # def on_predict_batch_begin(self, batch, logs=None):\n",
        "    #     keys = list(logs.keys())\n",
        "    #     print(\"...Predicting: start of batch {}; got log keys: {}\".format(batch, keys))\n",
        "\n",
        "    # def on_predict_batch_end(self, batch, logs=None):\n",
        "    #     keys = list(logs.keys())\n",
        "    #     print(\"...Predicting: end of batch {}; got log keys: {}\".format(batch, keys))\n",
        "\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ESf_MDvqX8Q",
        "colab_type": "text"
      },
      "source": [
        "###### tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NArOfPTCqcEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import datetime\n",
        "from packaging import version\n",
        "\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yhQk9OgqfYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install -U tensorboard_plugin_profile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gc3v95J4qm3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a TensorBoard callback\n",
        "logs = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
        "                                                 histogram_freq = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JFR48CMq1-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the TensorBoard notebook extension.\n",
        "%reload_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwJspzkfq4us",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Launch TensorBoard and navigate to the Profile tab to view performance profile\n",
        "%tensorboard --logdir=logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qv2K06PA73dr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!export TF_GPU_THREAD_MODE=gpu_private"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NG1oXaqoCPL-",
        "colab_type": "text"
      },
      "source": [
        "###### train\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZDs11EH8vpU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "5ccd45bb-717f-44d3-a71d-e44a5e0888f8"
      },
      "source": [
        "print(hidden_units, dropout_rate, embed_dim, learning_rate,batch_size)\n",
        "print(num_students, num_skills, max_sequence_length, num_batches)\n",
        "\n",
        "model.fit(train_dataset.prefetch(6),  epochs=1,  validation_data=val_dataset)#,  callbacks=[CustomCallback()])"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200 0.2 200 0.005 50\n",
            "28118 265 2089 562\n",
            "966/966 [==============================] - 90s 94ms/step - loss: 1341.8607 - auc_5: 0.6090 - binary_crossentropy: 0.6258 - val_loss: 2153.4209 - val_auc_5: 0.6067 - val_binary_crossentropy: 0.6006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f90911d5400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjqPMX_J8Q95",
        "colab_type": "text"
      },
      "source": [
        "###### evaluate with test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgTatxF__Xl_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = model.evaluate(val_dataset.prefetch(5), callbacks=[CustomCallback()])\n",
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFsb4uOoMtHE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "cellView": "both",
        "outputId": "1593e438-22c6-4c02-a524-635ccbe6f7db"
      },
      "source": [
        "print(hidden_units, dropout_rate, embed_dim, learning_rate,batch_size)\n",
        "print(num_students, num_skills, max_sequence_length, num_batches)\n",
        "\n",
        "model.fit(train_dataset.prefetch(6),  epochs=1,  validation_data=val_dataset)#,  callbacks=[CustomCallback()])\n",
        "# model.fit(input_label_dataset.take(200).prefetch(1), epochs=1, callbacks=[tboard_callback])\n",
        "\n",
        "# model.evaluate(input_label_dataset.take(1))"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200 0.2 200 0.004 50\n",
            "28118 265 2089 562\n",
            "966/966 [==============================] - 90s 94ms/step - loss: 1271.3989 - auc_3: 0.6504 - binary_crossentropy: 0.5930 - val_loss: 2188.6274 - val_auc_3: 0.5910 - val_binary_crossentropy: 0.6104\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9096ddb588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9Rc4XGLr5Nn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_test_data = input_label_dataset.take(1)\n",
        "y_pred = model.predict(sample_test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t3UXt5aGmkE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sample_test_data = test_dataset.take(1)\n",
        "# y_true = list(sample_test_data.as_numpy_iterator())\n",
        "y_true = y_true[0][1]['outputs']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxfWm6k5spS4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = tf.keras.metrics.AUC()\n",
        "m.update_state(y_true, y_pred)\n",
        "print(m.result().numpy())\n",
        "bce = tf.keras.losses.BinaryCrossentropy()\n",
        "print(bce(y_true, y_pred).numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cp6IfWgkShh9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(sample_test_data)\n",
        "y_true_arr = y_true[0][1]['outputs'][0].T[0][0:82]\n",
        "y_pred_arr = y_pred[0].T[0][0:82]\n",
        "print(y_true_arr)\n",
        "print(y_pred_arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEOLB1iNhnZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_true_arr2 = y_true[1][1]['outputs'][0].T[0][0:15]\n",
        "y_pred_arr2= y_pred[0].T[0][0:15]\n",
        "print(y_true_arr2)\n",
        "print(y_pred_arr2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7j7frZcCg3WI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_true = np.concatenate((y_true_arr, y_true_arr2))\n",
        "y_pred = np.concatenate((y_pred_arr, y_pred_arr2))\n",
        "m = tf.keras.metrics.AUC()\n",
        "m.update_state(y_true, y_pred)\n",
        "print(m.result().numpy())\n",
        "bce = tf.keras.losses.BinaryCrossentropy()\n",
        "print(bce(y_true, y_pred).numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEuL9-qc853E",
        "colab_type": "text"
      },
      "source": [
        "### codes for debugging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HtXG-itC_cV",
        "colab_type": "text"
      },
      "source": [
        "##### checking metric and loss with raw(=masked) sample dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7VZD1EP89Fh",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuRFIAol1bqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.evaluate(train_dataset, batch_size=3)\n",
        "predictions = model.predict(train_dataset)\n",
        "\n",
        "print(\"raw labels\")\n",
        "A = np.array([[1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1]]).T\n",
        "Y_pred =np.concatenate((predictions[0][0:3], predictions[1][0:5], predictions[2][0:6]))\n",
        "print(F\"shapes, {A.shape}, {Y_pred.shape}, len: {len(A)}\")\n",
        "print(A.T,Y_pred.T)\n",
        "\n",
        "\n",
        "print(\"correct AUC\")\n",
        "m = tf.keras.metrics.AUC()\n",
        "m.update_state(A,Y_pred)\n",
        "print(m.result().numpy())\n",
        "print()\n",
        "\n",
        "print(\"correct metric loss for each sample\")\n",
        "m = tf.keras.metrics.BinaryCrossentropy()\n",
        "m.update_state(A,Y_pred)\n",
        "print(m.result().numpy())\n",
        "print()\n",
        "\n",
        "print(\"correct loss of keras loss, SUM\")\n",
        "\n",
        "# loss masked\n",
        "bce = tf.keras.losses.BinaryCrossentropy()\n",
        "print(bce(A,Y_pred).numpy())\n",
        "\n",
        "print(\"loss SUM\")\n",
        "bce = tf.keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.SUM)\n",
        "print(bce(A,Y_pred).numpy())\n",
        "print(bce.get_config())\n",
        "\n",
        "# print()\n",
        "# print(\"loss from inside model\")\n",
        "# bce = model.loss\n",
        "# print(\"SUM\")\n",
        "# print(model.loss(A, Y_pred).numpy())\n",
        "# print(model.loss.get_config())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blWU79alKjjQ",
        "colab_type": "text"
      },
      "source": [
        "##### build model class base( WARNING: run only on numpy input data )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noIRVpKZjRbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# FIXME:  evaluate cause an error below\n",
        "# step=1 does not work\n",
        "\"\"\"\n",
        "WARNING:tensorflow:8 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7f55ca8a7a60>\n",
        " triggered tf.function retracing. \n",
        " Tracing is expensive and the excessive number of tracings could be due to \n",
        " (1) creating @tf.function repeatedly in a loop,\n",
        " (2) passing tensors with different shapes,\n",
        "  (3) passing Python objects instead of tensors. \n",
        "  For (1), please define your @tf.function outside of the loop.\n",
        "   For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. \n",
        "   For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args \n",
        "   and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
        "\"\"\"\n",
        "class DKT(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.x = tf.keras.Input(shape=(max_sequence_length, num_skills*2), name='x')\n",
        "    self.q = tf.keras.Input(shape=(max_sequence_length, num_skills), name='q')\n",
        "    self.inputs = [self.x , self.q]\n",
        "    # self.x = tf.keras.Input(shape=(None, max_sequence_length, num_skills*2), name='inputs')\n",
        "    # self.q = tf.keras.Input(shape=(None, max_sequence_length, num_skills), name='labels')\n",
        "\n",
        "    self.emb =  layers.Dense(embed_dim, trainable=False, \n",
        "                                                        kernel_initializer=tf.keras.initializers.RandomNormal(seed=777),\n",
        "                                                        input_shape=(None, max_sequence_length, num_skills*2))\n",
        "    self.mask = layers.Masking(mask_value=0)\n",
        "    self.lstm =  layers.LSTM(hidden_units, return_sequences=True)\n",
        "    self.out_dropout =  layers.TimeDistributed(layers.Dropout(dropout_rate))\n",
        "    self.out_sigmoid =  layers.TimeDistributed(layers.Dense(num_skills,  activation='sigmoid'))\n",
        "\n",
        "    # HACK: the shape of q does not fit to Timedistributed operation(may be faster?)\n",
        "    self.dot =  layers.Multiply()\n",
        "    # self.dot =  layers.TimeDistributed(layers.Multiply())\n",
        "\n",
        "    #self.reduce_sum = tf.reduce_sum\n",
        "    #self.transpose = tf.transpose\n",
        "\n",
        "    self.reduce_sum =  layers.Dense(1, trainable=False, \n",
        "                                                        kernel_initializer=tf.keras.initializers.constant(value=1),\n",
        "                                                        input_shape=(None, max_sequence_length,num_skills))\n",
        "    # reshape layer does not work as graph \n",
        "    # self.reshape_l = layers.Reshape((-1,3),dynamic=False)#, \n",
        "    #                                                      # input_shape=(None,max_sequence_length,num_skills,))\n",
        "    self.final_mask =   layers.TimeDistributed(\n",
        "      layers.Masking(mask_value=0, input_shape=(None, max_sequence_length,1))\n",
        "    )\n",
        "\n",
        "\n",
        "  def call(self, inputs):\n",
        "    self.inputs= inputs\n",
        "    x , q = self.inputs['x'], self.inputs[\"q\"]\n",
        "    # x = inputs\n",
        "    # x, q = inputs\n",
        "    # self.x, self.q = inputs[0], inputs[1]\n",
        "    # n = self.emb(x)\n",
        "    n = self.emb(self.x)\n",
        "    masked_n = self.mask(n)\n",
        "    h = self.lstm(masked_n) \n",
        "    o = self.out_dropout(h)\n",
        "    y_pred = self.out_sigmoid(o)\n",
        "\n",
        "    #\n",
        "    # q = tf.slice(x, [0, 0, 0], [-1, -1, num_skills])  \n",
        "    # y_pred = self.dot([y_pred, q])\n",
        "    y_pred = self.dot([y_pred, self.q])\n",
        "    # y_pred = self.reduce_sum(y_pred, axis=2)\n",
        "    y_pred = self.reduce_sum(y_pred)\n",
        "    #y_pred = self.reshape_l(y_pred)\n",
        "    #y_pred = self.transpose()\n",
        "    y_pred = self.final_mask(y_pred)\n",
        "    #y_pred._keras_mask=masked_n._keras_mask\n",
        "    return y_pred\n",
        "\n",
        "# Create an instance of the model\n",
        "model = DKT()\n",
        "\n",
        "# Configuration of model\n",
        "# Set \"SUM\" to loss reduction in order to use distributed training\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.SUM),\n",
        "                optimizer=tf.optimizers.SGD(learning_rate=learning_rate),\n",
        "                metrics=[tf.keras.metrics.AUC()])\n",
        "                # metrics=[tf.keras.metrics.AUC(),tf.keras.metrics.BinaryCrossentropy()]) # keep for debug loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ahr37F7zPeJo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "one_data = input_label_dataset.take(1)\n",
        "a,b = one_data[0],one_data[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxeT_xv5wJ66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize and check model structure\n",
        "predictions = model([one_hot_input, one_hot_q_t])\n",
        "# predictions = model(input_label_dataset)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFhrPWLy9DpT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check the shapes of outputs\n",
        "q = one_hot_q_t\n",
        "n = model.emb(one_hot_input)\n",
        "print(tf.shape(n))\n",
        "masked_n = model.mask(n)\n",
        "print(tf.shape(masked_n))\n",
        "h = model.lstm(masked_n) \n",
        "print(tf.shape(h))\n",
        "o = model.out_dropout(h)\n",
        "y_pred = model.out_sigmoid(o)\n",
        "print(tf.shape(y_pred))\n",
        "y_pred = model.dot([y_pred, q])\n",
        "print(tf.shape(y_pred))\n",
        "y_pred = model.reduce_sum(y_pred)\n",
        "print(tf.shape(y_pred))\n",
        "y_pred = model.mask(y_pred)\n",
        "print(tf.shape(y_pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nn87mZVO8-sn",
        "colab_type": "text"
      },
      "source": [
        "##### Check prediction and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4ha1CJrr6nM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predictions = model([one_hot_input, one_hot_q_t])\n",
        "# predictions = model(one_hot_input)\n",
        "predictions = model(train_dataset)\n",
        "\n",
        "# check masking works correctly\n",
        "# print(predictions._keras_mask.numpy())\n",
        "# print(padded_inputs)\n",
        "print()\n",
        "\n",
        "# check shape of predicted vector\n",
        "print(\"predcitions shape:\")\n",
        "print(predictions.shape) #num_student, T, M(num_skill or num_problem)\n",
        "print(predictions, padded_labels)\n",
        "print()\n",
        "\n",
        "# TODO: avoid reshape before feeding\n",
        "padded_labels = tf.reshape(padded_labels,(len(raw_labels),6,1))\n",
        "#padded_labels = tf.transpose(padded_labels)\n",
        "print(padded_labels.shape)\n",
        "model.evaluate([one_hot_input, one_hot_q_t], padded_labels , verbose =2, steps=1)\n",
        "# model.evaluate(one_hot_input, padded_labels , verbose =2, steps=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxlLaAKzvYzb",
        "colab_type": "text"
      },
      "source": [
        "##### Check the metrics and loss works correctly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Rw_rDUD2WIh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(train_dataset)\n",
        "\n",
        "m = tf.keras.metrics.AUC()\n",
        "# print(\"sample dataset\")\n",
        "# m.update_state([0, 0, 1, 1], [0, 0.5, 0.3, 0.9])\n",
        "# print(m.result().numpy())\n",
        "\n",
        "\n",
        "print(\"orignal built-in\")\n",
        "# reshaped_labels = tf.reshape(padded_labels, [6,3])\n",
        "# reshaped_predictions = tf.reshape(predictions, [6,3])\n",
        "m.update_state(padded_labels,predictions)\n",
        "print(m.result().numpy())\n",
        "# print(len(padded_labels))\n",
        "\"\"\"\n",
        "print(\"each instance with masking\")\n",
        "m = tf.keras.metrics.AUC()\n",
        "print([1, 1, 1], tf.transpose(predictions[0][0:3]))\n",
        "m.update_state([[1, 1, 1]], tf.transpose(predictions[0][0:3]))\n",
        "print(m.result().numpy())\n",
        "\n",
        "m = tf.keras.metrics.AUC()\n",
        "print(padded_labels[1][0:5],predictions[1][0:5])\n",
        "m.update_state(padded_labels[1][0:5],predictions[1][0:5])\n",
        "print(m.result().numpy())\n",
        "\n",
        "m = tf.keras.metrics.AUC()\n",
        "print(padded_labels[2][0:6],predictions[2][0:6])\n",
        "m.update_state(padded_labels[2][0:6],predictions[2][0:6])\n",
        "print(m.result().numpy())\n",
        "\"\"\"\n",
        "print(\"all with masking\")\n",
        "A =  [1, 1, 1, 0, 0, 0, 1, 1,  0, 1, 1, 1, 0, 1]\n",
        "Y_pred =np.concatenate((predictions[0][0:3], predictions[1][0:5], predictions[2][0:6]))\n",
        "# A = tf.reshape(padded_labels, [-1])\n",
        "# Y_pred = predictions\n",
        "print(A,Y_pred.T)\n",
        "print(\"correct AUC\")\n",
        "m = tf.keras.metrics.AUC()\n",
        "m.update_state(A,Y_pred)\n",
        "print(m.result().numpy())\n",
        "print()\n",
        "\n",
        "\n",
        "# debug for loss function \n",
        "\"\"\"\n",
        "# sample \n",
        "print((np.log(0.4)*3 + np.log(0.6)*1)/4)\n",
        "print(raw_labels, predictions[0][0:3])\n",
        "\n",
        "# normal loss\n",
        "bce = tf.keras.losses.BinaryCrossentropy()\n",
        "print(bce(padded_labels[0][0:3],predictions[0][0:3]).numpy())\n",
        "\"\"\"\n",
        "#print(np.log(0.5)*3)\n",
        "# loss SUM\n",
        "print(\"original built-in\")\n",
        "bce = tf.keras.losses.BinaryCrossentropy()\n",
        "print(bce(A,Y_pred).numpy())\n",
        "print(\"without mask\")\n",
        "print(bce(padded_labels,predictions).numpy())\n",
        "print(\"loss SUM\")\n",
        "bce = tf.keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.SUM)\n",
        "print(bce(A,Y_pred).numpy())\n",
        "print(\"without mask\")\n",
        "print(bce(padded_labels,predictions).numpy())\n",
        "#total = bce(np.zeros(3), np.ones(3))*3 - np.log(0.5)*3\n",
        "#total/6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKuVk96IdLUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i23H9qy9MCRR",
        "colab_type": "text"
      },
      "source": [
        "##### check how masking is probagated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJdohG_SWYBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check how masking is probagated\n",
        "q = one_hot_q_t\n",
        "n = model.emb(one_hot_input)\n",
        "masked_n = model.mask(n)\n",
        "h = model.lstm(masked_n) \n",
        "print(h._keras_mask)\n",
        "o = model.out_dropout(h)\n",
        "print(o._keras_mask)\n",
        "y_pred = model.out_sigmoid(o)\n",
        "print(y_pred._keras_mask)\n",
        "y_pred = model.dot([y_pred, q])\n",
        "print(y_pred._keras_mask)\n",
        "y_pred = model.reduce_sum(y_pred)\n",
        "print(y_pred._keras_mask)\n",
        "y_pred = model.mask(y_pred)\n",
        "print(y_pred._keras_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADazFVziMEzq",
        "colab_type": "text"
      },
      "source": [
        "##### fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7uEYQUQypdH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit([one_hot_input, one_hot_q_t], padded_labels, epochs=50 ,verbose =1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgQIAGpY7i7m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model([one_hot_input, one_hot_q_t]).numpy()\n",
        "print(predictions)\n",
        "print(padded_labels)\n",
        "print(raw_labels)\n",
        "model.evaluate([one_hot_input, one_hot_q_t], padded_labels ,verbose =2)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}